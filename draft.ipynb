{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "# imports and some initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "emotion_map = {\n",
    "  0: 'Angry',\n",
    "  1: 'Disgust',\n",
    "  2: 'Fear',\n",
    "  3: 'Happy',\n",
    "  4: 'Sad',\n",
    "  5: 'Surprise',\n",
    "  6: 'Neutral'\n",
    "}\n",
    "\n",
    "train_data_raw = pd.read_csv('datasets/fer2013/train.csv')\n",
    "test_data_raw = pd.read_csv('datasets/fer2013/test.csv')\n",
    "\n",
    "# create a data generator to not load all images into memory\n",
    "def data_generator(data, batch_size=32):\n",
    "  while True:\n",
    "    for start in range(0, len(data), batch_size):\n",
    "      end = min(start + batch_size, len(data))\n",
    "      batch_data = data[start:end]\n",
    "      batch_features = []\n",
    "      batch_labels = []\n",
    "      for _, row in batch_data.iterrows():\n",
    "        img = np.array(row['pixels'].split(), 'float32').reshape(48, 48)\n",
    "        img /= 255.0 \n",
    "        img_expanded = np.expand_dims(img, axis=-1)\n",
    "        img_rgb = np.repeat(img_expanded, 3, axis=-1)\n",
    "        batch_features.append(img_rgb)\n",
    "        batch_labels.append(row['emotion'])\n",
    "      yield np.stack(batch_features), to_categorical(batch_labels, num_classes=len(emotion_map))\n",
    "\n",
    "train_generator = data_generator(train_data_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m456/897\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 182ms/step - accuracy: 0.1524 - loss: 2.7389 - precision: 0.1584 - recall: 0.0083"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2  # Import l2 regularizer\n",
    "\n",
    "# Load the EfficientNetB0 model pre-trained on ImageNet, excluding the top layers\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Ensure the output shape matches the target shape\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(emotion_map), activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# adding temporary unfreeze for testing\n",
    "for layer in base_model.layers[-40:]:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-7), loss='categorical_crossentropy', metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "  rotation_range=10,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.1,\n",
    "  horizontal_flip=True,\n",
    "  brightness_range=[0.8, 1.2],\n",
    "  fill_mode='nearest'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "\n",
    "def augmented_data_generator(generator, datagen, batch_size=32):\n",
    "  while True:\n",
    "    # Get a batch from the custom generator\n",
    "    batch_features, batch_labels = next(generator)\n",
    "    # Use the datagen.flow to augment the batch\n",
    "    augmented_data = datagen.flow(batch_features, batch_labels, batch_size=batch_size, shuffle=False)\n",
    "    # Yield the augmented batch\n",
    "    yield next(augmented_data)\n",
    "\n",
    "train_generator_augmented = augmented_data_generator(data_generator(train_data_raw), datagen)\n",
    "\n",
    "# Fit the model using the data generator\n",
    "model.fit(\n",
    "  train_generator_augmented,\n",
    "  steps_per_epoch=len(train_data_raw) // 32,\n",
    "  epochs=30,\n",
    "  callbacks=[early_stopping, reduce_lr],\n",
    "  validation_data=augmented_data_generator(data_generator(test_data_raw), datagen),\n",
    "  validation_steps=len(test_data_raw) // 32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "for index, row in test_data_raw.iterrows():\n",
    "  test_features.append(np.array(row['pixels'].split(), 'float32').reshape(48, 48, 1))\n",
    "  test_labels.append(row['emotion'])\n",
    "\n",
    "test_labels_categorical = to_categorical(test_labels, num_classes=len(emotion_map))\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(np.array(test_features), test_labels_categorical)\n",
    "print(f\"Test Loss: {evaluation[0]}\")\n",
    "print(f\"Test Accuracy: {evaluation[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# predict using the model on a real image\n",
    "def predict_emotion(img_path):\n",
    "  img = image.load_img(img_path, target_size=(48, 48), color_mode='grayscale')\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_array = np.expand_dims(img_array, axis=0)\n",
    "  img_array = np.repeat(img_array, 3, axis=-1)  # Convert grayscale to 3 channels\n",
    "\n",
    "  prediction = model.predict(img_array)\n",
    "  predicted_emotion = emotion_map[np.argmax(prediction)]\n",
    "  \n",
    "  plt.imshow(img, cmap='gray')\n",
    "  plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "# Example usage\n",
    "predict_emotion('path_to_your_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification_model(model, np.array(test_features), test_labels_categorical, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
