{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "# imports and some initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "emotion_map = {\n",
    "  0: 'Angry',\n",
    "  1: 'Disgust',\n",
    "  2: 'Fear',\n",
    "  3: 'Happy',\n",
    "  4: 'Sad',\n",
    "  5: 'Surprise',\n",
    "  6: 'Neutral'\n",
    "}\n",
    "\n",
    "train_data_raw = pd.read_csv('datasets/fer2013/train.csv')\n",
    "test_data_raw = pd.read_csv('datasets/fer2013/test.csv')\n",
    "\n",
    "# create a data generator to not load all images into memory\n",
    "def data_generator(data, batch_size=32):\n",
    "  while True:\n",
    "    for start in range(0, len(data), batch_size):\n",
    "      end = min(start + batch_size, len(data))\n",
    "      batch_data = data[start:end]\n",
    "      batch_features = []\n",
    "      batch_labels = []\n",
    "      for _, row in batch_data.iterrows():\n",
    "        img = np.array(row['pixels'].split(), 'float32').reshape(48, 48)\n",
    "        img /= 255.0 \n",
    "        img_expanded = np.expand_dims(img, axis=-1)\n",
    "        img_rgb = np.repeat(img_expanded, 3, axis=-1)\n",
    "        batch_features.append(img_rgb)\n",
    "        batch_labels.append(row['emotion'])\n",
    "      yield np.stack(batch_features), to_categorical(batch_labels, num_classes=len(emotion_map))\n",
    "\n",
    "train_generator = data_generator(train_data_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 226ms/step - accuracy: 0.1608 - loss: 2.6954 - precision: 0.1805 - recall: 0.0080 - val_accuracy: 0.2680 - val_loss: 2.3995 - val_precision: 0.6061 - val_recall: 0.0056 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 217ms/step - accuracy: 0.2253 - loss: 2.4844 - precision: 0.4352 - recall: 0.0208 - val_accuracy: 0.3010 - val_loss: 2.3340 - val_precision: 0.6825 - val_recall: 0.0463 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 211ms/step - accuracy: 0.2611 - loss: 2.4093 - precision: 0.5269 - recall: 0.0370 - val_accuracy: 0.3269 - val_loss: 2.2912 - val_precision: 0.6694 - val_recall: 0.0680 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 192ms/step - accuracy: 0.2801 - loss: 2.3703 - precision: 0.5752 - recall: 0.0481 - val_accuracy: 0.3497 - val_loss: 2.2541 - val_precision: 0.7118 - val_recall: 0.0750 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 190ms/step - accuracy: 0.3012 - loss: 2.3365 - precision: 0.5901 - recall: 0.0555 - val_accuracy: 0.3651 - val_loss: 2.2221 - val_precision: 0.7070 - val_recall: 0.0851 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 216ms/step - accuracy: 0.3194 - loss: 2.2936 - precision: 0.6308 - recall: 0.0680 - val_accuracy: 0.3792 - val_loss: 2.1876 - val_precision: 0.6902 - val_recall: 0.1013 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 223ms/step - accuracy: 0.3308 - loss: 2.2623 - precision: 0.6389 - recall: 0.0808 - val_accuracy: 0.3853 - val_loss: 2.1597 - val_precision: 0.7008 - val_recall: 0.1187 - learning_rate: 1.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 227ms/step - accuracy: 0.3402 - loss: 2.2441 - precision: 0.6336 - recall: 0.0909 - val_accuracy: 0.3969 - val_loss: 2.1362 - val_precision: 0.7155 - val_recall: 0.1278 - learning_rate: 1.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 222ms/step - accuracy: 0.3557 - loss: 2.2157 - precision: 0.6445 - recall: 0.0980 - val_accuracy: 0.4058 - val_loss: 2.1130 - val_precision: 0.7186 - val_recall: 0.1376 - learning_rate: 1.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 217ms/step - accuracy: 0.3630 - loss: 2.1919 - precision: 0.6436 - recall: 0.1058 - val_accuracy: 0.4026 - val_loss: 2.0997 - val_precision: 0.7086 - val_recall: 0.1426 - learning_rate: 1.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 221ms/step - accuracy: 0.3700 - loss: 2.1732 - precision: 0.6586 - recall: 0.1125 - val_accuracy: 0.4176 - val_loss: 2.0794 - val_precision: 0.7088 - val_recall: 0.1485 - learning_rate: 1.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 230ms/step - accuracy: 0.3711 - loss: 2.1536 - precision: 0.6713 - recall: 0.1183 - val_accuracy: 0.4202 - val_loss: 2.0678 - val_precision: 0.7158 - val_recall: 0.1551 - learning_rate: 1.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 241ms/step - accuracy: 0.3861 - loss: 2.1359 - precision: 0.6567 - recall: 0.1258 - val_accuracy: 0.4198 - val_loss: 2.0471 - val_precision: 0.7155 - val_recall: 0.1580 - learning_rate: 1.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 246ms/step - accuracy: 0.3835 - loss: 2.1206 - precision: 0.6564 - recall: 0.1298 - val_accuracy: 0.4181 - val_loss: 2.0373 - val_precision: 0.7058 - val_recall: 0.1655 - learning_rate: 1.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 210ms/step - accuracy: 0.3931 - loss: 2.1072 - precision: 0.6769 - recall: 0.1321 - val_accuracy: 0.4214 - val_loss: 2.0242 - val_precision: 0.7175 - val_recall: 0.1671 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 203ms/step - accuracy: 0.3983 - loss: 2.0905 - precision: 0.6712 - recall: 0.1400 - val_accuracy: 0.4303 - val_loss: 2.0080 - val_precision: 0.7179 - val_recall: 0.1720 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 206ms/step - accuracy: 0.3989 - loss: 2.0668 - precision: 0.6819 - recall: 0.1448 - val_accuracy: 0.4257 - val_loss: 2.0088 - val_precision: 0.7007 - val_recall: 0.1825 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 207ms/step - accuracy: 0.4066 - loss: 2.0593 - precision: 0.6776 - recall: 0.1513 - val_accuracy: 0.4316 - val_loss: 1.9898 - val_precision: 0.7071 - val_recall: 0.1828 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 202ms/step - accuracy: 0.4092 - loss: 2.0451 - precision: 0.6723 - recall: 0.1513 - val_accuracy: 0.4316 - val_loss: 1.9732 - val_precision: 0.7021 - val_recall: 0.1850 - learning_rate: 1.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 208ms/step - accuracy: 0.4078 - loss: 2.0302 - precision: 0.6775 - recall: 0.1560 - val_accuracy: 0.4341 - val_loss: 1.9627 - val_precision: 0.7151 - val_recall: 0.1847 - learning_rate: 1.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 223ms/step - accuracy: 0.4119 - loss: 2.0258 - precision: 0.6736 - recall: 0.1551 - val_accuracy: 0.4397 - val_loss: 1.9402 - val_precision: 0.7230 - val_recall: 0.1917 - learning_rate: 1.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 211ms/step - accuracy: 0.4138 - loss: 2.0066 - precision: 0.6727 - recall: 0.1599 - val_accuracy: 0.4456 - val_loss: 1.9380 - val_precision: 0.7249 - val_recall: 0.1903 - learning_rate: 1.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 220ms/step - accuracy: 0.4153 - loss: 1.9932 - precision: 0.6741 - recall: 0.1655 - val_accuracy: 0.4430 - val_loss: 1.9305 - val_precision: 0.7061 - val_recall: 0.2047 - learning_rate: 1.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 217ms/step - accuracy: 0.4209 - loss: 1.9789 - precision: 0.6717 - recall: 0.1644 - val_accuracy: 0.4409 - val_loss: 1.9113 - val_precision: 0.7178 - val_recall: 0.1979 - learning_rate: 1.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 227ms/step - accuracy: 0.4248 - loss: 1.9675 - precision: 0.6802 - recall: 0.1738 - val_accuracy: 0.4502 - val_loss: 1.9013 - val_precision: 0.7167 - val_recall: 0.2078 - learning_rate: 1.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 240ms/step - accuracy: 0.4265 - loss: 1.9570 - precision: 0.6905 - recall: 0.1757 - val_accuracy: 0.4568 - val_loss: 1.8848 - val_precision: 0.7215 - val_recall: 0.2099 - learning_rate: 1.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 224ms/step - accuracy: 0.4311 - loss: 1.9440 - precision: 0.6851 - recall: 0.1807 - val_accuracy: 0.4519 - val_loss: 1.8709 - val_precision: 0.7432 - val_recall: 0.2142 - learning_rate: 1.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 213ms/step - accuracy: 0.4269 - loss: 1.9383 - precision: 0.6790 - recall: 0.1815 - val_accuracy: 0.4614 - val_loss: 1.8672 - val_precision: 0.7185 - val_recall: 0.2128 - learning_rate: 1.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 213ms/step - accuracy: 0.4337 - loss: 1.9305 - precision: 0.6819 - recall: 0.1815 - val_accuracy: 0.4524 - val_loss: 1.8604 - val_precision: 0.7179 - val_recall: 0.2119 - learning_rate: 1.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 232ms/step - accuracy: 0.4325 - loss: 1.9180 - precision: 0.6735 - recall: 0.1824 - val_accuracy: 0.4632 - val_loss: 1.8498 - val_precision: 0.7177 - val_recall: 0.2191 - learning_rate: 1.0000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 229ms/step - accuracy: 0.4411 - loss: 1.9030 - precision: 0.6884 - recall: 0.1884 - val_accuracy: 0.4603 - val_loss: 1.8341 - val_precision: 0.7179 - val_recall: 0.2208 - learning_rate: 1.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 232ms/step - accuracy: 0.4421 - loss: 1.8940 - precision: 0.6945 - recall: 0.1971 - val_accuracy: 0.4563 - val_loss: 1.8344 - val_precision: 0.7109 - val_recall: 0.2302 - learning_rate: 1.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 233ms/step - accuracy: 0.4486 - loss: 1.8841 - precision: 0.6865 - recall: 0.1963 - val_accuracy: 0.4583 - val_loss: 1.8257 - val_precision: 0.7253 - val_recall: 0.2243 - learning_rate: 1.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 236ms/step - accuracy: 0.4412 - loss: 1.8806 - precision: 0.6891 - recall: 0.1960 - val_accuracy: 0.4604 - val_loss: 1.8081 - val_precision: 0.7299 - val_recall: 0.2299 - learning_rate: 1.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 235ms/step - accuracy: 0.4461 - loss: 1.8598 - precision: 0.6939 - recall: 0.2001 - val_accuracy: 0.4666 - val_loss: 1.8034 - val_precision: 0.7292 - val_recall: 0.2280 - learning_rate: 1.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 225ms/step - accuracy: 0.4533 - loss: 1.8443 - precision: 0.7048 - recall: 0.2071 - val_accuracy: 0.4699 - val_loss: 1.8004 - val_precision: 0.7100 - val_recall: 0.2368 - learning_rate: 1.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 214ms/step - accuracy: 0.4491 - loss: 1.8404 - precision: 0.7003 - recall: 0.2054 - val_accuracy: 0.4632 - val_loss: 1.7953 - val_precision: 0.7076 - val_recall: 0.2385 - learning_rate: 1.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 215ms/step - accuracy: 0.4528 - loss: 1.8369 - precision: 0.7029 - recall: 0.2088 - val_accuracy: 0.4713 - val_loss: 1.7750 - val_precision: 0.7132 - val_recall: 0.2324 - learning_rate: 1.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 215ms/step - accuracy: 0.4597 - loss: 1.8164 - precision: 0.7049 - recall: 0.2104 - val_accuracy: 0.4750 - val_loss: 1.7742 - val_precision: 0.6927 - val_recall: 0.2382 - learning_rate: 1.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 214ms/step - accuracy: 0.4566 - loss: 1.8193 - precision: 0.6969 - recall: 0.2126 - val_accuracy: 0.4710 - val_loss: 1.7624 - val_precision: 0.7206 - val_recall: 0.2386 - learning_rate: 1.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 214ms/step - accuracy: 0.4594 - loss: 1.8122 - precision: 0.6947 - recall: 0.2133 - val_accuracy: 0.4696 - val_loss: 1.7561 - val_precision: 0.7139 - val_recall: 0.2483 - learning_rate: 1.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 212ms/step - accuracy: 0.4652 - loss: 1.7912 - precision: 0.7040 - recall: 0.2231 - val_accuracy: 0.4766 - val_loss: 1.7451 - val_precision: 0.7173 - val_recall: 0.2510 - learning_rate: 1.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 214ms/step - accuracy: 0.4625 - loss: 1.7877 - precision: 0.6967 - recall: 0.2200 - val_accuracy: 0.4807 - val_loss: 1.7405 - val_precision: 0.7153 - val_recall: 0.2485 - learning_rate: 1.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 219ms/step - accuracy: 0.4621 - loss: 1.7798 - precision: 0.6980 - recall: 0.2217 - val_accuracy: 0.4780 - val_loss: 1.7454 - val_precision: 0.6979 - val_recall: 0.2541 - learning_rate: 1.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 216ms/step - accuracy: 0.4671 - loss: 1.7691 - precision: 0.6995 - recall: 0.2255 - val_accuracy: 0.4761 - val_loss: 1.7295 - val_precision: 0.7000 - val_recall: 0.2520 - learning_rate: 1.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 217ms/step - accuracy: 0.4757 - loss: 1.7595 - precision: 0.7041 - recall: 0.2282 - val_accuracy: 0.4699 - val_loss: 1.7275 - val_precision: 0.7085 - val_recall: 0.2494 - learning_rate: 1.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 216ms/step - accuracy: 0.4725 - loss: 1.7532 - precision: 0.7101 - recall: 0.2301 - val_accuracy: 0.4800 - val_loss: 1.7161 - val_precision: 0.7268 - val_recall: 0.2531 - learning_rate: 1.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 222ms/step - accuracy: 0.4710 - loss: 1.7489 - precision: 0.6957 - recall: 0.2266 - val_accuracy: 0.4800 - val_loss: 1.7159 - val_precision: 0.7182 - val_recall: 0.2510 - learning_rate: 1.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 219ms/step - accuracy: 0.4712 - loss: 1.7523 - precision: 0.6961 - recall: 0.2296 - val_accuracy: 0.4800 - val_loss: 1.7073 - val_precision: 0.7110 - val_recall: 0.2568 - learning_rate: 1.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 221ms/step - accuracy: 0.4773 - loss: 1.7335 - precision: 0.7048 - recall: 0.2327 - val_accuracy: 0.4811 - val_loss: 1.7075 - val_precision: 0.7101 - val_recall: 0.2571 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14935d2d4e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import json\n",
    "\n",
    "# Load the EfficientNetB0 model pre-trained on ImageNet, excluding the top layers\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(emotion_map), activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# adding temporary unfreeze for testing\n",
    "for layer in base_model.layers[-30:]:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "  rotation_range=10,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.1,\n",
    "  horizontal_flip=True,\n",
    "  brightness_range=[0.8, 1.2],\n",
    "  fill_mode='nearest'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "\n",
    "def augmented_data_generator(generator, datagen, batch_size=32):\n",
    "  while True:\n",
    "    # Get a batch from the custom generator\n",
    "    batch_features, batch_labels = next(generator)\n",
    "    # Use the datagen.flow to augment the batch\n",
    "    augmented_data = datagen.flow(batch_features, batch_labels, batch_size=batch_size, shuffle=False)\n",
    "    # Yield the augmented batch\n",
    "    yield next(augmented_data)\n",
    "\n",
    "train_generator_augmented = augmented_data_generator(data_generator(train_data_raw), datagen, 64)\n",
    "\n",
    "# Fit the model using the data generator\n",
    "history = model.fit(\n",
    "  train_generator_augmented,\n",
    "  steps_per_epoch=len(train_data_raw) // 64,\n",
    "  epochs=30,\n",
    "  callbacks=[early_stopping, reduce_lr],\n",
    "  validation_data=augmented_data_generator(data_generator(test_data_raw), datagen),\n",
    "  validation_steps=len(test_data_raw) // 64,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('fer2013_efficientNetB3.keras')\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "for index, row in test_data_raw.iterrows():\n",
    "  img = np.array(row['pixels'].split(), 'float32').reshape(48, 48)\n",
    "  img /= 255.0 \n",
    "  img_expanded = np.expand_dims(img, axis=-1)\n",
    "  img_rgb = np.repeat(img_expanded, 3, axis=-1)\n",
    "  test_features.append(img_rgb)\n",
    "  test_labels.append(row['emotion'])\n",
    "\n",
    "test_labels_categorical = to_categorical(test_labels, num_classes=len(emotion_map))\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(np.array(test_features), test_labels_categorical)\n",
    "print(f\"Test Loss: {evaluation[0]}\")\n",
    "print(f\"Test Accuracy: {evaluation[1]}\")\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(to_categorical(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfer+efficientNetB3.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m test_features \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "def evaluate_classification_model(model, test_features, test_labels, class_names):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model and generates key metrics and visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained Keras/TensorFlow model.\n",
    "    - test_features: Numpy array of test features.\n",
    "    - test_labels: Numpy array of one-hot encoded test labels.\n",
    "    - class_names: List of class names corresponding to emotions.\n",
    "    \n",
    "    Returns:\n",
    "    - None (generates visualizations and prints metrics).\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict classes and probabilities\n",
    "    predictions = model.predict(test_features)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(test_labels, axis=1)\n",
    "    \n",
    "    # Generate the classification report for precision, recall, F1 Score\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_names)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve and AUC\n",
    "    n_classes = len(class_names)\n",
    "    true_classes_binarized = label_binarize(true_classes, classes=range(n_classes))\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_classes_binarized[:, i], predictions[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Each Emotion')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(n_classes):\n",
    "        precision, recall, _ = precision_recall_curve(true_classes_binarized[:, i], predictions[:, i])\n",
    "        plt.plot(recall, precision, label=f'Precision-Recall curve of class {class_names[i]}')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve for Each Emotion')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Training/Validation Curves\n",
    "    history = model.history.history  # Assuming you saved the `history` during training\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Accuracy Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Loss Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "emotion_list = [\n",
    "'Angry',\n",
    "'Disgust',\n",
    "'Fear',\n",
    "'Happy',\n",
    "'Sad',\n",
    "'Surprise',\n",
    "'Neutral'\n",
    "]\n",
    "\n",
    "evaluate_classification_model(model, test_features, test_labels, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# predict using the model on a real image\n",
    "def predict_emotion(img_path):\n",
    "  img = image.load_img(img_path, target_size=(48, 48), color_mode='grayscale')\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_array = np.expand_dims(img_array, axis=0)\n",
    "  img_array = np.repeat(img_array, 3, axis=-1)  # Convert grayscale to 3 channels\n",
    "\n",
    "  prediction = model.predict(img_array)\n",
    "  predicted_emotion = emotion_map[np.argmax(prediction)]\n",
    "  \n",
    "  plt.imshow(img, cmap='gray')\n",
    "  plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "# Example usage\n",
    "predict_emotion('path_to_your_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification_model(model, np.array(test_features), test_labels_categorical, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
