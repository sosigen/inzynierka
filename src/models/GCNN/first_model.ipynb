{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from spektral.utils.convolution import gcn_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic configuration\n",
    "BATCH_SIZE = 32\n",
    "dataset_path = 'fer2013plus'\n",
    "img_size = 48           # FER2013 images are 48x48\n",
    "patch_size = 6          # Using 6x6 patches → 8x8 grid = 64 nodes\n",
    "color_mode = 'grayscale'\n",
    "\n",
    "# Create ImageDataGenerator for training/validation\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    fill_mode='constant',\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Training subset\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    f'{dataset_path}/train',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    color_mode=color_mode,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation subset\n",
    "validation_generator = train_data_generator.flow_from_directory(\n",
    "    f'{dataset_path}/train',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    color_mode=color_mode,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Test generator (no augmentation, just rescaling)\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    f'{dataset_path}/test',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    color_mode=color_mode,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Modified function to create a grid adjacency matrix with diagonal connections\n",
    "def create_grid_adj_matrix(n_rows, n_cols, self_loop=True):\n",
    "    \"\"\"\n",
    "    Create adjacency matrix for an n_rows x n_cols grid.\n",
    "    Each node is connected to its 8 immediate neighbors (if available).\n",
    "    \"\"\"\n",
    "    n_nodes = n_rows * n_cols\n",
    "    A = np.zeros((n_nodes, n_nodes), dtype=np.float32)\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            idx = r * n_cols + c\n",
    "            if self_loop:\n",
    "                A[idx, idx] = 1.0\n",
    "            # Iterate over all 8 possible neighbors\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    if dr == 0 and dc == 0:\n",
    "                        continue  # skip self\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if 0 <= nr < n_rows and 0 <= nc < n_cols:\n",
    "                        neighbor_idx = nr * n_cols + nc\n",
    "                        A[idx, neighbor_idx] = 1.0\n",
    "    return A\n",
    "\n",
    "# Modified function to convert an image into graph patches with enriched features\n",
    "def image_to_graph(image, patch_size):\n",
    "    \"\"\"\n",
    "    Split an image into non-overlapping patches, flatten each patch, and append\n",
    "    the normalized (x,y) coordinates of the patch center.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    n_rows = h // patch_size\n",
    "    n_cols = w // patch_size\n",
    "    \n",
    "    image_tensor = tf.convert_to_tensor(image)\n",
    "    image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=image_tensor,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'\n",
    "    )\n",
    "    # patches shape: (1, n_rows, n_cols, patch_size*patch_size*c)\n",
    "    patches = tf.reshape(patches, (-1, patch_size * patch_size * image.shape[-1]))\n",
    "    patches_np = patches.numpy()  # shape: (n_rows*n_cols, patch_size*patch_size*c)\n",
    "    \n",
    "    # Append normalized (x, y) coordinates for each patch\n",
    "    coords = []\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            # Center coordinates normalized to [0,1]\n",
    "            x_center = (c * patch_size + patch_size/2) / w\n",
    "            y_center = (r * patch_size + patch_size/2) / h\n",
    "            coords.append([x_center, y_center])\n",
    "    coords = np.array(coords)\n",
    "    \n",
    "    # Concatenate patch pixel values with coordinates\n",
    "    # New node feature dimension = patch_size*patch_size*c + 2.\n",
    "    patches_np = np.concatenate([patches_np, coords], axis=1)\n",
    "    return patches_np\n",
    "\n",
    "# Generator that wraps the original ImageDataGenerator and outputs graph data\n",
    "def graph_generator(original_generator, patch_size, img_size):\n",
    "    \"\"\"\n",
    "    For each batch:\n",
    "      - Convert images to enriched node features (including patch pixels and coordinates)\n",
    "      - Attach a fixed adjacency matrix (using grid connectivity with diagonals)\n",
    "    \"\"\"\n",
    "    n_rows = img_size // patch_size  # e.g., 48/6 = 8\n",
    "    n_cols = img_size // patch_size  # 8 columns → 64 nodes\n",
    "    # Create and preprocess the enhanced adjacency matrix\n",
    "    A = create_grid_adj_matrix(n_rows, n_cols, self_loop=True)\n",
    "    A = gcn_filter(A)\n",
    "    \n",
    "    while True:\n",
    "        images, labels = next(original_generator)\n",
    "        batch_size = images.shape[0]\n",
    "        node_features_list = []\n",
    "        for i in range(batch_size):\n",
    "            nodes = image_to_graph(images[i], patch_size)\n",
    "            node_features_list.append(nodes)\n",
    "        X_batch = np.array(node_features_list)  # shape: (batch_size, 64, patch_size*patch_size*c+2)\n",
    "        A_batch = np.array([A] * batch_size)      # shape: (batch_size, 64, 64)\n",
    "        yield ((X_batch, A_batch), labels)\n",
    "\n",
    "# Define output signature for tf.data.Dataset\n",
    "# For grayscale images: channels = 1, so initial patch feature dim = 6*6*1 = 36, then +2 for coordinates → 38.\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=(None, 64, patch_size*patch_size + 2), dtype=tf.float32),\n",
    "     tf.TensorSpec(shape=(None, 64, 64), dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(None, 8), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: graph_generator(train_generator, patch_size, img_size),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: graph_generator(validation_generator, patch_size, img_size),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: graph_generator(test_generator, patch_size, img_size),\n",
    "    output_signature=output_signature\n",
    ")\n",
    "\n",
    "# Test sample prints\n",
    "print(\"Train dataset sample:\")\n",
    "for (X, y) in train_dataset.take(1):\n",
    "    node_features, adj_matrices = X\n",
    "    print(\"  Node features shape:\", node_features.shape)   # Expected: (BATCH_SIZE, 64, 38)\n",
    "    print(\"  Adjacency shape:\", adj_matrices.shape)           # Expected: (BATCH_SIZE, 64, 64)\n",
    "    print(\"  Labels shape:\", y.shape)                         # Expected: (BATCH_SIZE, 8)\n",
    "\n",
    "print(\"\\nValidation dataset sample:\")\n",
    "for (X, y) in validation_dataset.take(1):\n",
    "    node_features, adj_matrices = X\n",
    "    print(\"  Node features shape:\", node_features.shape)\n",
    "    print(\"  Adjacency shape:\", adj_matrices.shape)\n",
    "    print(\"  Labels shape:\", y.shape)\n",
    "\n",
    "print(\"\\nTest dataset sample:\")\n",
    "for (X, y) in test_dataset.take(1):\n",
    "    node_features, adj_matrices = X\n",
    "    print(\"  Node features shape:\", node_features.shape)\n",
    "    print(\"  Adjacency shape:\", adj_matrices.shape)\n",
    "    print(\"  Labels shape:\", y.shape)\n",
    "\n",
    "# Optionally, retrieve one example image for visualization\n",
    "example_images, _ = next(train_generator)\n",
    "example_img = example_images[0].squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.layers import GlobalAvgPool, GlobalMaxPool, GCNConv\n",
    "\n",
    "# Custom subclass to ignore masks in GCNConv\n",
    "class NoMaskGCNConv(GCNConv):\n",
    "    def call(self, inputs, mask=None):\n",
    "        # Ignore any provided mask\n",
    "        return super().call(inputs, mask=None)\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Do not propagate any mask\n",
    "        return None\n",
    "\n",
    "def build_gcn_model(n_node_features, n_classes, num_nodes):\n",
    "    # Inputs for node features and adjacency matrix\n",
    "    x_in = tf.keras.Input(shape=(num_nodes, n_node_features), name=\"node_features\")\n",
    "    a_in = tf.keras.Input(shape=(num_nodes, num_nodes), name=\"adjacency_matrix\")\n",
    "    \n",
    "    # First GCN layer with 32 filters using our custom layer\n",
    "    x1 = NoMaskGCNConv(32, activation='relu')([x_in, a_in])\n",
    "    # Second GCN layer with 64 filters\n",
    "    x2 = NoMaskGCNConv(64, activation='relu')([x1, a_in])\n",
    "    \n",
    "    # Global pooling: max and average\n",
    "    x_max = GlobalMaxPool()(x2)\n",
    "    x_mean = GlobalAvgPool(name='global_avg_pool')(x2)\n",
    "    # Concatenate the pooled features\n",
    "    x_concat = Concatenate()([x_max, x_mean])\n",
    "    \n",
    "    # Fully connected layer and final classification layer\n",
    "    x_fc = Dense(256, activation='relu')(x_concat)\n",
    "    output = Dense(n_classes, activation='softmax')(x_fc)\n",
    "    \n",
    "    model = Model(inputs=[x_in, a_in], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Parameters derived from earlier cells:\n",
    "# With patch_size=3 on a 48x48 image, we have a 16x16 grid => 256 nodes.\n",
    "img_size = 48\n",
    "patch_size = 6\n",
    "num_nodes = (img_size // patch_size) ** 2  # 16^2 = 256\n",
    "n_node_features = patch_size * patch_size    # 3x3 = 9 features per node (grayscale)\n",
    "n_classes = 8  # Update to 8 classes\n",
    "\n",
    "model = build_gcn_model(n_node_features=n_node_features, n_classes=n_classes, num_nodes=num_nodes)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "activation_logger = ActivationLogger(train_dataset, \"global_avg_pool\")\n",
    "\n",
    "# ----------------- Training -----------------\n",
    "# Callbacks for robust training\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=len(validation_generator),\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, reduce_lr, activation_logger]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
