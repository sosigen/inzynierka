{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Loss: 1.0770130157470703\n",
    "Test Accuracy: 0.6356924176216125\n",
    "\n",
    "Epoch 30/30\n",
    "448/448 ━━━━━━━━━━━━━━━━━━━━ 45s 100ms/step - accuracy: 0.2452 - loss: 2.4779 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2492 - val_loss: 2.4545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
    "\n",
    "filename: efficientnet_b3_60_l_67%.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and some initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "emotion_map = {\n",
    "  0: 'Angry',\n",
    "  1: 'Disgust',\n",
    "  2: 'Fear',\n",
    "  3: 'Happy',\n",
    "  4: 'Sad',\n",
    "  5: 'Surprise',\n",
    "  6: 'Neutral'\n",
    "}\n",
    "\n",
    "train_data_raw = pd.read_csv('train.csv')\n",
    "test_data_raw = pd.read_csv('test.csv')\n",
    "\n",
    "# create a data generator to not load all images into memory\n",
    "def data_generator(data, batch_size=32):\n",
    "  while True:\n",
    "    for start in range(0, len(data), batch_size):\n",
    "      end = min(start + batch_size, len(data))\n",
    "      batch_data = data[start:end]\n",
    "      batch_features = []\n",
    "      batch_labels = []\n",
    "      for _, row in batch_data.iterrows():\n",
    "        img = np.array(row['pixels'].split(), 'float32').reshape(48, 48)\n",
    "        img /= 255.0\n",
    "        img_expanded = np.expand_dims(img, axis=-1)\n",
    "        img_rgb = np.repeat(img_expanded, 3, axis=-1)\n",
    "        batch_features.append(img_rgb)\n",
    "        batch_labels.append(row['emotion'])\n",
    "      yield np.stack(batch_features), to_categorical(batch_labels, num_classes=len(emotion_map))\n",
    "\n",
    "train_generator = data_generator(train_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "max_epochs_per_stage = 30\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Load the EfficientNetB5 model pre-trained on ImageNet, excluding the top layers\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Add custom top layers with higher dropout rates\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.5)(x)  # Increased dropout\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.6)(x)  # Increased dropout\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.3)(x) \n",
    "predictions = Dense(len(emotion_map), activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers initially\n",
    "for layer in base_model.layers[-60:]:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Compile with initial settings\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation suited for facial expression data\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to augment data\n",
    "def augmented_data_generator(generator, datagen, batch_size=32):\n",
    "    while True:\n",
    "        batch_features, batch_labels = next(generator)\n",
    "        augmented_data = datagen.flow(batch_features, batch_labels, batch_size=batch_size, shuffle=False)\n",
    "        yield next(augmented_data)\n",
    "\n",
    "train_generator_augmented = augmented_data_generator(data_generator(train_data_raw), datagen, BATCH_SIZE)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator_augmented,\n",
    "    steps_per_epoch=len(train_data_raw) // BATCH_SIZE,\n",
    "    epochs=max_epochs_per_stage,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    validation_data=augmented_data_generator(data_generator(test_data_raw), datagen),\n",
    "    validation_steps=len(test_data_raw) // BATCH_SIZE,\n",
    ")\n",
    "\n",
    "\n",
    "# Save the final model after modular unfreezing\n",
    "model.save('efficientnetb5_finetuned_model.h5')\n",
    "print(\"Model fine-tuning complete and saved as 'efficientnetb5_finetuned_model_2.h5'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Re-create test features and labels with consistent preprocessing\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for _, row in test_data_raw.iterrows():\n",
    "    img = np.array(row['pixels'].split(), 'float32').reshape(48, 48)\n",
    "    img /= 255.0  # normalize\n",
    "    img_expanded = np.expand_dims(img, axis=-1)\n",
    "    img_rgb = np.repeat(img_expanded, 3, axis=-1)\n",
    "    test_features.append(img_rgb)\n",
    "    test_labels.append(row['emotion'])\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "test_labels_categorical = to_categorical(test_labels, num_classes=len(emotion_map))\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(test_features, test_labels_categorical, batch_size=BATCH_SIZE)\n",
    "print(f\"Test Loss: {evaluation[0]}\")\n",
    "print(f\"Test Accuracy: {evaluation[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
