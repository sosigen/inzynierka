{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VudeAWcpkzhA",
    "outputId": "55e8100f-7a65-44a2-d141-0c141eda53f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to /content\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "def unzip_file(zip_path, extract_to='.'):\n",
    "    \"\"\"\n",
    "    Unzips the specified archive to the target directory.\n",
    "\n",
    "    Parameters:\n",
    "    zip_path (str): Path to the .zip file.\n",
    "    extract_to (str): Directory where files will be extracted. Default is the current directory.\n",
    "    \"\"\"\n",
    "    # Check if the specified path is a valid zip file\n",
    "    if zipfile.is_zipfile(zip_path):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f'Files extracted to {os.path.abspath(extract_to)}')\n",
    "    else:\n",
    "        print(f\"{zip_path} is not a valid zip file.\")\n",
    "\n",
    "unzip_file('DATASET.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4owO5fgji-g8",
    "outputId": "18f4d64b-b050-4d14-f3fe-b73b1ab85ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "Found 12271 images belonging to 7 classes.\n",
      "Found 3067 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "test_labels = pd.read_csv(f'test_labels.csv')\n",
    "train_labels = pd.read_csv(f'train_labels.csv')\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0/255,   # Normalize pixel values between 0 and 1\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    directory='DATASET/train',\n",
    "    target_size=(100, 100),   # Resize images to 100x100\n",
    "    color_mode='rgb',         # Specify that images are in RGB\n",
    "    batch_size=32,            # Adjust this batch size as needed\n",
    "    class_mode='categorical', # Use 'categorical' for multi-class classification\n",
    "    subset='training'         # Use the 'training' subset\n",
    ")\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1.0/255)  # Only rescaling for test data\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    directory='DATASET/test',\n",
    "    target_size=(100, 100),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "emotion_labels = {\n",
    "    0: \"Surprise\",\n",
    "    1: \"Fear\",\n",
    "    2: \"Disgust\",\n",
    "    3: \"Happiness\",\n",
    "    4: \"Sadness\",\n",
    "    5: \"Anger\",\n",
    "    6: \"Neutral\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0vcGPUmlWcs"
   },
   "outputs": [],
   "source": [
    "# test train generator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a batch of images and labels from the generator\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "# Plot a few images to check if augmentation and loading are correct\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):  # Display the first 9 images in the batch\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i])  # Display image\n",
    "    plt.title(f\"Class: {emotion_labels[np.argmax(labels[i])]}\")\n",
    "    plt.title(f\"Class: {emotion_labels[np.argmax(labels[i])]}\")\n",
    "    plt.axis('off')  # Hide axis\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mSBWZrZow8p",
    "outputId": "165e8bc3-ad58-4c25-c866-9b55189f797f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.1896 - loss: 3.4481 - precision: 0.2013 - recall: 0.0572 - val_accuracy: 0.3861 - val_loss: 2.6708 - val_precision: 0.3861 - val_recall: 0.3861 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 2s/step - accuracy: 0.3076 - loss: 2.7417 - precision: 0.3411 - recall: 0.0675 - val_accuracy: 0.3858 - val_loss: 2.4165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.3350 - loss: 2.5127 - precision: 0.3516 - recall: 0.0632 - val_accuracy: 0.3876 - val_loss: 2.3010 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.3422 - loss: 2.3468 - precision: 0.3175 - recall: 0.0403 - val_accuracy: 0.3864 - val_loss: 2.1775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 1s/step - accuracy: 0.3584 - loss: 2.2557 - precision: 0.3311 - recall: 0.0336 - val_accuracy: 0.3871 - val_loss: 2.0970 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 1s/step - accuracy: 0.3805 - loss: 2.1229 - precision: 0.3948 - recall: 0.0356 - val_accuracy: 0.3851 - val_loss: 2.0267 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 1s/step - accuracy: 0.3817 - loss: 2.0624 - precision: 0.3672 - recall: 0.0215 - val_accuracy: 0.3869 - val_loss: 1.9777 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 1s/step - accuracy: 0.3673 - loss: 2.0232 - precision: 0.2979 - recall: 0.0108 - val_accuracy: 0.3848 - val_loss: 1.9236 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.3832 - loss: 1.9493 - precision: 0.3541 - recall: 0.0183 - val_accuracy: 0.3866 - val_loss: 1.8861 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 1s/step - accuracy: 0.3905 - loss: 1.9040 - precision: 0.3848 - recall: 0.0131 - val_accuracy: 0.3874 - val_loss: 1.8488 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 1s/step - accuracy: 0.3986 - loss: 1.8743 - precision: 0.4184 - recall: 0.0178 - val_accuracy: 0.3843 - val_loss: 1.8194 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.3707 - loss: 1.8354 - precision: 0.3467 - recall: 0.0084 - val_accuracy: 0.3892 - val_loss: 1.7858 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.3858 - loss: 1.8184 - precision: 0.3330 - recall: 0.0080 - val_accuracy: 0.3866 - val_loss: 1.7706 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 1s/step - accuracy: 0.3779 - loss: 1.8044 - precision: 0.3455 - recall: 0.0054 - val_accuracy: 0.3869 - val_loss: 1.7404 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 1s/step - accuracy: 0.3948 - loss: 1.7699 - precision: 0.4446 - recall: 0.0159 - val_accuracy: 0.3879 - val_loss: 1.7293 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.3842 - loss: 1.7531 - precision: 0.3337 - recall: 0.0029 - val_accuracy: 0.3820 - val_loss: 1.7201 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.3852 - loss: 1.7395 - precision: 0.3359 - recall: 0.0042 - val_accuracy: 0.3874 - val_loss: 1.7020 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 1s/step - accuracy: 0.3924 - loss: 1.7252 - precision: 0.2582 - recall: 0.0052 - val_accuracy: 0.3851 - val_loss: 1.6917 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 1s/step - accuracy: 0.3940 - loss: 1.7014 - precision: 0.4360 - recall: 0.0130 - val_accuracy: 0.3884 - val_loss: 1.6854 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.3855 - loss: 1.7198 - precision: 0.4461 - recall: 0.0062 - val_accuracy: 0.3851 - val_loss: 1.6792 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.3886 - loss: 1.6970 - precision: 0.4025 - recall: 0.0080 - val_accuracy: 0.3889 - val_loss: 1.6717 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.3913 - loss: 1.6949 - precision: 0.2954 - recall: 0.0039 - val_accuracy: 0.3822 - val_loss: 1.6815 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 1s/step - accuracy: 0.3798 - loss: 1.6954 - precision: 0.2243 - recall: 0.0032 - val_accuracy: 0.3889 - val_loss: 1.6624 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 1s/step - accuracy: 0.3816 - loss: 1.7053 - precision: 0.5244 - recall: 0.0063 - val_accuracy: 0.3874 - val_loss: 1.6636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.3984 - loss: 1.6687 - precision: 0.3899 - recall: 0.0109 - val_accuracy: 0.3866 - val_loss: 1.6581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 1s/step - accuracy: 0.3955 - loss: 1.6719 - precision: 0.4549 - recall: 0.0074 - val_accuracy: 0.3864 - val_loss: 1.6575 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.3831 - loss: 1.6833 - precision: 0.1393 - recall: 0.0012 - val_accuracy: 0.3815 - val_loss: 1.6610 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 1s/step - accuracy: 0.3842 - loss: 1.6875 - precision: 0.4007 - recall: 0.0041 - val_accuracy: 0.3912 - val_loss: 1.6491 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 1s/step - accuracy: 0.3869 - loss: 1.6791 - precision: 0.3525 - recall: 0.0051 - val_accuracy: 0.3846 - val_loss: 1.6641 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 1s/step - accuracy: 0.3941 - loss: 1.6688 - precision: 0.2971 - recall: 0.0030 - val_accuracy: 0.3918 - val_loss: 1.6470 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# create the model and train\n",
    "from tensorflow.keras.applications import EfficientNetV2B0  # Importing EfficientNetV2B0 for a smaller model version\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the EfficientNetV2 base model with imagenet weights\n",
    "base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = BatchNormalization()(x)  # Adding batch normalization\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = BatchNormalization()(x)  # Adding batch normalization\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = BatchNormalization()(x)  # Adding batch normalization\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)  # Assuming 7 emotion classes\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers initially for transfer learning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Optionally, unfreeze the last few layers for fine-tuning\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model with an adaptive optimizer and additional metrics\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # Set an initial learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "\n",
    "# Custom data generator with augmentations\n",
    "def augmented_data_generator(generator, datagen, batch_size=32):\n",
    "    while True:\n",
    "        batch_features, batch_labels = next(generator)\n",
    "        augmented_data = datagen.flow(batch_features, batch_labels, batch_size=batch_size, shuffle=False)\n",
    "        yield next(augmented_data)\n",
    "\n",
    "# Training and testing data generators with augmentation applied\n",
    "train_generator = augmented_data_generator(train_generator, data_gen, 64)\n",
    "val_generator = augmented_data_generator(test_generator, data_gen, 64)\n",
    "\n",
    "# Early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=12271 // 64,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=12271 // 64,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYcm65I0s4yW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_classification_model(model, generator, class_names):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model and generates key metrics and visualizations.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained Keras/TensorFlow model.\n",
    "    - generator: ImageDataGenerator that yields test data and labels.\n",
    "    - class_names: List of class names corresponding to emotions.\n",
    "\n",
    "    Returns:\n",
    "    - None (generates visualizations and prints metrics).\n",
    "    \"\"\"\n",
    "    # Get predictions and true labels from the generator\n",
    "    predictions = model.predict(generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Retrieve true labels from the generator\n",
    "    true_classes = generator.classes\n",
    "    true_classes_binarized = label_binarize(true_classes, classes=range(len(class_names)))\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_names)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve and AUC\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(len(class_names)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_classes_binarized[:, i], predictions[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Each Emotion')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(len(class_names)):\n",
    "        precision, recall, _ = precision_recall_curve(true_classes_binarized[:, i], predictions[:, i])\n",
    "        plt.plot(recall, precision, label=f'Precision-Recall curve of class {class_names[i]}')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve for Each Emotion')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "\n",
    "    # Training/Validation Curves\n",
    "    history = model.history.history  # Use the saved `history` attribute from training\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Accuracy Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Loss Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Running evaluation with your model, test generator, and emotion labels\n",
    "evaluate_classification_model(model, test_generator, list(emotion_labels.values()))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
