{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n",
    "                                     BatchNormalization, Activation)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Phase 1\n",
    "model.add(Conv2D(64, (3, 1), strides=(1, 1), padding='same', input_shape=(48, 48, 3)))\n",
    "model.add(Conv2D(64, (1, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Phase 2\n",
    "model.add(Conv2D(128, (3, 1), strides=(1, 1), padding='same'))\n",
    "model.add(Conv2D(128, (1, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Phase 3\n",
    "model.add(Conv2D(256, (3, 1), strides=(1, 1), padding='same'))\n",
    "model.add(Conv2D(256, (1, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Phase 4\n",
    "model.add(Conv2D(512, (3, 1), strides=(1, 1), padding='same'))\n",
    "model.add(Conv2D(512, (1, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Phase 5\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Phase 6\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Phase 7 (Output Layer)\n",
    "model.add(Dense(len(emotion_map), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    mode='max',              # We want to maximize accuracy\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=int(25838 / 32),\n",
    "    epochs=25,\n",
    "    callbacks=[reduce_lr, checkpoint, early_stopping],\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=int(2871 / 32)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "Epoch 1/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.2672 - loss: 1.9168\n",
    "Epoch 1: val_accuracy improved from -inf to 0.17154, saving model to best_model.keras\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 45s 40ms/step - accuracy: 0.2673 - loss: 1.9164 - val_accuracy: 0.1715 - val_loss: 2.1762 - learning_rate: 0.0010\n",
    "Epoch 2/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.4418 - loss: 1.4534\n",
    "Epoch 2: val_accuracy improved from 0.17154 to 0.17189, saving model to best_model.keras\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 21s 26ms/step - accuracy: 0.4419 - loss: 1.4533 - val_accuracy: 0.1719 - val_loss: 2.3046 - learning_rate: 0.0010\n",
    "Epoch 3/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.5009 - loss: 1.3049\n",
    "Epoch 3: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 29ms/step - accuracy: 0.5009 - loss: 1.3048 - val_accuracy: 0.1705 - val_loss: 1.9798 - learning_rate: 0.0010\n",
    "Epoch 4/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.5344 - loss: 1.2248\n",
    "Epoch 4: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 28ms/step - accuracy: 0.5344 - loss: 1.2248 - val_accuracy: 0.1708 - val_loss: 1.9717 - learning_rate: 0.0010\n",
    "Epoch 5/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.5569 - loss: 1.1742\n",
    "Epoch 5: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 29ms/step - accuracy: 0.5569 - loss: 1.1742 - val_accuracy: 0.1715 - val_loss: 2.0296 - learning_rate: 0.0010\n",
    "Epoch 6/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.5695 - loss: 1.1345\n",
    "Epoch 6: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 29ms/step - accuracy: 0.5695 - loss: 1.1345 - val_accuracy: 0.1708 - val_loss: 1.9436 - learning_rate: 0.0010\n",
    "Epoch 7/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.5843 - loss: 1.0922\n",
    "Epoch 7: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 29ms/step - accuracy: 0.5843 - loss: 1.0922 - val_accuracy: 0.1715 - val_loss: 1.9790 - learning_rate: 0.0010\n",
    "Epoch 8/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.6020 - loss: 1.0520\n",
    "Epoch 8: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 30ms/step - accuracy: 0.6020 - loss: 1.0520 - val_accuracy: 0.1708 - val_loss: 1.8857 - learning_rate: 0.0010\n",
    "Epoch 9/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.6179 - loss: 1.0130\n",
    "Epoch 9: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 22s 27ms/step - accuracy: 0.6179 - loss: 1.0129 - val_accuracy: 0.1708 - val_loss: 1.9859 - learning_rate: 0.0010\n",
    "Epoch 10/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.6271 - loss: 0.9789\n",
    "Epoch 10: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 25s 30ms/step - accuracy: 0.6271 - loss: 0.9789 - val_accuracy: 0.1391 - val_loss: 2.0994 - learning_rate: 0.0010\n",
    "Epoch 11/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.6456 - loss: 0.9403\n",
    "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
    "\n",
    "Epoch 11: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 29ms/step - accuracy: 0.6457 - loss: 0.9403 - val_accuracy: 0.1374 - val_loss: 1.9985 - learning_rate: 0.0010\n",
    "Epoch 12/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.6765 - loss: 0.8633\n",
    "Epoch 12: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 20s 25ms/step - accuracy: 0.6766 - loss: 0.8631 - val_accuracy: 0.1384 - val_loss: 2.1311 - learning_rate: 2.0000e-04\n",
    "Epoch 13/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.6989 - loss: 0.7934\n",
    "Epoch 13: val_accuracy did not improve from 0.17189\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 25s 30ms/step - accuracy: 0.6989 - loss: 0.7933 - val_accuracy: 0.1388 - val_loss: 2.1748 - learning_rate: 2.0000e-04"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
