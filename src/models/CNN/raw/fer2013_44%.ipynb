{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements? Expand augmentation, L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "SIZE_FACE=48\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input and first convolutional block\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                 input_shape=(48, 48, 3),\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third convolutional block\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fourth convolutional block\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer=RandomNormal(stddev=1),\n",
    "                 bias_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(emotion_map), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "  filepath='best_model_resnet2.keras',  # Path to save the model\n",
    "  monitor='val_loss',                 # Metric to monitor\n",
    "  mode='max',                         # 'min' for loss, 'max' for accuracy\n",
    "  save_best_only=True,                # Save only the best weights\n",
    "  verbose=1                           # Display a message when a model is saved\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=25838 // 32,\n",
    "    epochs=25,\n",
    "    callbacks=[reduce_lr, checkpoint],\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=2871 // 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.2055 - loss: 2.9125\n",
    "Epoch 1: val_loss improved from -inf to 2.02452, saving model to best_model_resnet2.keras\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 45s 40ms/step - accuracy: 0.2056 - loss: 2.9106 - val_accuracy: 0.2518 - val_loss: 2.0245 - learning_rate: 0.0010\n",
    "Epoch 2/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.2394 - loss: 1.8206\n",
    "Epoch 2: val_loss improved from 2.02452 to 2.15394, saving model to best_model_resnet2.keras\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 22s 28ms/step - accuracy: 0.2394 - loss: 1.8206 - val_accuracy: 0.2607 - val_loss: 2.1539 - learning_rate: 0.0010\n",
    "Epoch 3/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.2473 - loss: 1.8015\n",
    "Epoch 3: val_loss improved from 2.15394 to 2.44191, saving model to best_model_resnet2.keras\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 25s 31ms/step - accuracy: 0.2473 - loss: 1.8015 - val_accuracy: 0.2642 - val_loss: 2.4419 - learning_rate: 0.0010\n",
    "Epoch 4/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.2521 - loss: 1.7861\n",
    "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
    "\n",
    "Epoch 4: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 25s 31ms/step - accuracy: 0.2521 - loss: 1.7860 - val_accuracy: 0.2850 - val_loss: 2.1343 - learning_rate: 0.0010\n",
    "Epoch 5/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.2773 - loss: 1.7505\n",
    "Epoch 5: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 21s 26ms/step - accuracy: 0.2773 - loss: 1.7505 - val_accuracy: 0.3089 - val_loss: 2.0017 - learning_rate: 2.0000e-04\n",
    "Epoch 6/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.2848 - loss: 1.7301\n",
    "Epoch 6: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 26s 32ms/step - accuracy: 0.2848 - loss: 1.7301 - val_accuracy: 0.3258 - val_loss: 1.8421 - learning_rate: 2.0000e-04\n",
    "Epoch 7/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.3009 - loss: 1.6999\n",
    "Epoch 7: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 29ms/step - accuracy: 0.3010 - loss: 1.6999 - val_accuracy: 0.3322 - val_loss: 1.7793 - learning_rate: 2.0000e-04\n",
    "Epoch 8/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.3152 - loss: 1.6871\n",
    "Epoch 8: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 22s 27ms/step - accuracy: 0.3152 - loss: 1.6871 - val_accuracy: 0.3572 - val_loss: 1.7069 - learning_rate: 2.0000e-04\n",
    "Epoch 9/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.3241 - loss: 1.6654\n",
    "Epoch 9: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 28ms/step - accuracy: 0.3241 - loss: 1.6654 - val_accuracy: 0.3558 - val_loss: 1.7455 - learning_rate: 2.0000e-04\n",
    "Epoch 10/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.3379 - loss: 1.6455\n",
    "Epoch 10: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 28ms/step - accuracy: 0.3379 - loss: 1.6455 - val_accuracy: 0.3709 - val_loss: 1.6849 - learning_rate: 2.0000e-04\n",
    "Epoch 11/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.3510 - loss: 1.6252\n",
    "Epoch 11: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 29ms/step - accuracy: 0.3510 - loss: 1.6252 - val_accuracy: 0.3755 - val_loss: 1.7321 - learning_rate: 2.0000e-04\n",
    "Epoch 12/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.3599 - loss: 1.6107\n",
    "Epoch 12: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 21s 26ms/step - accuracy: 0.3599 - loss: 1.6107 - val_accuracy: 0.3973 - val_loss: 1.6554 - learning_rate: 2.0000e-04\n",
    "Epoch 13/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.3675 - loss: 1.5995\n",
    "Epoch 13: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 25s 31ms/step - accuracy: 0.3675 - loss: 1.5994 - val_accuracy: 0.3878 - val_loss: 1.6290 - learning_rate: 2.0000e-04\n",
    "Epoch 14/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.3737 - loss: 1.5846\n",
    "Epoch 14: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 21s 26ms/step - accuracy: 0.3737 - loss: 1.5846 - val_accuracy: 0.4086 - val_loss: 1.5841 - learning_rate: 2.0000e-04\n",
    "Epoch 15/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.3857 - loss: 1.5629\n",
    "Epoch 15: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 29ms/step - accuracy: 0.3857 - loss: 1.5628 - val_accuracy: 0.4132 - val_loss: 1.5457 - learning_rate: 2.0000e-04\n",
    "Epoch 16/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.3890 - loss: 1.5481\n",
    "Epoch 16: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 23s 28ms/step - accuracy: 0.3890 - loss: 1.5481 - val_accuracy: 0.4206 - val_loss: 1.5600 - learning_rate: 2.0000e-04\n",
    "Epoch 17/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.3950 - loss: 1.5345\n",
    "Epoch 17: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 22s 27ms/step - accuracy: 0.3950 - loss: 1.5345 - val_accuracy: 0.4333 - val_loss: 1.5667 - learning_rate: 2.0000e-04\n",
    "Epoch 18/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.4042 - loss: 1.5154\n",
    "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
    "\n",
    "Epoch 18: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 29ms/step - accuracy: 0.4042 - loss: 1.5154 - val_accuracy: 0.4357 - val_loss: 1.5557 - learning_rate: 2.0000e-04\n",
    "Epoch 19/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.4109 - loss: 1.5011\n",
    "Epoch 19: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 20s 25ms/step - accuracy: 0.4109 - loss: 1.5011 - val_accuracy: 0.4417 - val_loss: 1.5455 - learning_rate: 4.0000e-05\n",
    "Epoch 20/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.4130 - loss: 1.4962\n",
    "Epoch 20: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 29s 36ms/step - accuracy: 0.4130 - loss: 1.4962 - val_accuracy: 0.4378 - val_loss: 1.5648 - learning_rate: 4.0000e-05\n",
    "Epoch 21/25\n",
    "806/807 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.4233 - loss: 1.4841\n",
    "Epoch 21: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 29ms/step - accuracy: 0.4233 - loss: 1.4841 - val_accuracy: 0.4442 - val_loss: 1.5372 - learning_rate: 4.0000e-05\n",
    "Epoch 22/25\n",
    "804/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.4246 - loss: 1.4901\n",
    "Epoch 22: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 21s 25ms/step - accuracy: 0.4246 - loss: 1.4901 - val_accuracy: 0.4484 - val_loss: 1.5398 - learning_rate: 4.0000e-05\n",
    "Epoch 23/25\n",
    "805/807 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.4188 - loss: 1.4844\n",
    "Epoch 23: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 30ms/step - accuracy: 0.4188 - loss: 1.4843 - val_accuracy: 0.4477 - val_loss: 1.5326 - learning_rate: 4.0000e-05\n",
    "Epoch 24/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.4239 - loss: 1.4746\n",
    "Epoch 24: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 21s 26ms/step - accuracy: 0.4239 - loss: 1.4746 - val_accuracy: 0.4491 - val_loss: 1.5351 - learning_rate: 4.0000e-05\n",
    "Epoch 25/25\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.4234 - loss: 1.4790\n",
    "Epoch 25: val_loss did not improve from 2.44191\n",
    "807/807 ━━━━━━━━━━━━━━━━━━━━ 24s 30ms/step - accuracy: 0.4234 - loss: 1.4790 - val_accuracy: 0.4519 - val_loss: 1.5315 - learning_rate: 4.0000e-05"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
