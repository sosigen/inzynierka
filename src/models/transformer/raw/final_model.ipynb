{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Parameters\n",
    "image_size = 48\n",
    "patch_size = 4\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "embedding_dim = 64\n",
    "num_heads = 4\n",
    "mlp_hidden_dim = 128\n",
    "num_transformer_layers = 4\n",
    "num_classes = 7\n",
    "dropout_rate = 0.1\n",
    "\n",
    "class ReduceMeanLayer(layers.Layer):\n",
    "    def __init__(self, axis=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "    def call(self, x):\n",
    "        return tf.reduce_mean(x, axis=self.axis)\n",
    "\n",
    "# 1. Patch Embedding Layer\n",
    "class PatchExtractor(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        # images: (batch, height, width, channels)\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1,1,1,1],\n",
    "            padding='VALID'\n",
    "        )\n",
    "        # patches shape: (batch, h/p, w/p, patch_size*patch_size*channels)\n",
    "        patch_dims = tf.shape(patches)[-1]\n",
    "        # Flatten h/p and w/p:\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patches, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.embedding = layers.Dense(embedding_dim)\n",
    "\n",
    "        self.cls_token = self.add_weight(name=\"cls_token\", shape=[1, 1, embedding_dim])\n",
    "\n",
    "        self.pos_embedding = self.add_weight(\n",
    "          name=\"pos_embedding\",\n",
    "          shape=(1, num_patches+1, embedding_dim),\n",
    "          initializer='zeros',\n",
    "          trainable=True\n",
    "      )\n",
    "\n",
    "    def call(self, patch_inputs):\n",
    "        # patch_inputs: (batch, num_patches, patch_dims)\n",
    "        x = self.embedding(patch_inputs)\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        cls_tokens = tf.repeat(self.cls_token, repeats=batch_size, axis=0) # (batch, 1, embedding_dim)\n",
    "        x = tf.concat([cls_tokens, x], axis=1)\n",
    "        return x + self.pos_embedding\n",
    "\n",
    "# 2. Transformer Encoder Block\n",
    "def mlp(x, hidden_dim, dropout_rate):\n",
    "    x = layers.Dense(hidden_dim, activation='gelu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(embedding_dim)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, mlp_hidden_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp_block = keras.Sequential([\n",
    "            layers.Dense(mlp_hidden_dim, activation='gelu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(embedding_dim),\n",
    "            layers.Dropout(dropout_rate),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        # x: (batch, num_patches, embedding_dim)\n",
    "        # Self-attention\n",
    "        attn_output = self.attn(x, x)\n",
    "        x = x + attn_output\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # MLP\n",
    "        mlp_output = self.mlp_block(x)\n",
    "        x = x + mlp_output\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 3. Build the Model\n",
    "inputs = keras.Input(shape=(image_size, image_size, 1))\n",
    "patches = PatchExtractor(patch_size)(inputs)\n",
    "x = PatchEmbedding(num_patches, embedding_dim)(patches)\n",
    "\n",
    "for _ in range(num_transformer_layers):\n",
    "    x = TransformerEncoder(embedding_dim, num_heads, mlp_hidden_dim, dropout_rate)(x)\n",
    "\n",
    "x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "cls_representation = x[:, 0, :]\n",
    "x = layers.Dense(num_classes, activation='softmax')(cls_representation)\n",
    "\n",
    "model = keras.Model(inputs, x)\n",
    "model.summary()\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "]\n",
    "\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=15, callbacks=callbacks)\n",
    "\n",
    "# this version yields\n",
    "# 221/221 [==============================] - 10s 46ms/step - loss: 1.3991 - accuracy: 0.4515\n",
    "# Test Loss: 1.3990623950958252\n",
    "# Test Accuracy: 0.451475590467453"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
