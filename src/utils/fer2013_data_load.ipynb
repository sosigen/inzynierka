{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First version is w/o augments, second version has input augments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "Training set size: 25838\n",
      "Validation set size: 2871\n"
     ]
    }
   ],
   "source": [
    "# Imports and initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# sanity check\n",
    "print(tf.__version__)\n",
    "\n",
    "emotion_map = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "dataset_path = '../../datasets/fer2013/'\n",
    "\n",
    "# Load the raw data\n",
    "train_data_raw = pd.read_csv(f'{dataset_path}train.csv')\n",
    "test_data_raw = pd.read_csv(f'{dataset_path}test.csv')\n",
    "\n",
    "train_data, val_data = train_test_split(train_data_raw, test_size=0.1, random_state=np.random.randint(1000))\n",
    "\n",
    "# Create a data generator to load data without augmentation\n",
    "def data_generator(data, batch_size=32):\n",
    "    while True:\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            end = min(start + batch_size, len(data))\n",
    "            batch_data = data[start:end]\n",
    "            batch_features = []\n",
    "            batch_labels = []\n",
    "            for _, row in batch_data.iterrows():\n",
    "                img = np.array(row['pixels'].split(), 'float32').reshape(48, 48)\n",
    "                img /= 255.0\n",
    "                img_expanded = np.expand_dims(img, axis=-1)\n",
    "                img_rgb = np.repeat(img_expanded, 3, axis=-1)\n",
    "                batch_features.append(img_rgb)\n",
    "                batch_labels.append(row['emotion'])\n",
    "            yield np.stack(batch_features), to_categorical(batch_labels, num_classes=len(emotion_map))\n",
    "\n",
    "# Initialize the train generator\n",
    "train_generator = data_generator(train_data, batch_size=BATCH_SIZE)\n",
    "val_generator = data_generator(val_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "Training set size: 25838\n",
      "Validation set size: 2871\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# sanity check\n",
    "print(tf.__version__)\n",
    "\n",
    "emotion_map = {\n",
    "  0: 'Angry',\n",
    "  1: 'Disgust',\n",
    "  2: 'Fear',\n",
    "  3: 'Happy',\n",
    "  4: 'Sad',\n",
    "  5: 'Surprise',\n",
    "  6: 'Neutral'\n",
    "}\n",
    "\n",
    "dataset_path = '../../datasets/fer2013/'\n",
    "\n",
    "# Load the raw data\n",
    "train_data_raw = pd.read_csv(f'{dataset_path}train.csv')\n",
    "test_data_raw = pd.read_csv(f'{dataset_path}test.csv')\n",
    "\n",
    "train_data, val_data = train_test_split(train_data_raw, test_size=0.1, random_state=np.random.randint(1000))\n",
    "\n",
    "# create a data generator to not load all images into memory\n",
    "def data_generator(data, batch_size=32):\n",
    "  while True:\n",
    "    for start in range(0, len(data), batch_size):\n",
    "      end = min(start + batch_size, len(data))\n",
    "      batch_data = data[start:end]\n",
    "      batch_features = []\n",
    "      batch_labels = []\n",
    "      for _, row in batch_data.iterrows():\n",
    "        img = np.array(row['pixels'].split(), 'float32').reshape(48, 48)\n",
    "        img /= 255.0\n",
    "        img_expanded = np.expand_dims(img, axis=-1)\n",
    "        img_rgb = np.repeat(img_expanded, 3, axis=-1)\n",
    "        batch_features.append(img_rgb)\n",
    "        batch_labels.append(row['emotion'])\n",
    "      yield np.stack(batch_features), to_categorical(batch_labels, num_classes=len(emotion_map))\n",
    "\n",
    "train_generator = data_generator(train_data, BATCH_SIZE)\n",
    "val_generator = data_generator(val_data, BATCH_SIZE)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def augmented_data_generator(generator, datagen, batch_size=32):\n",
    "    while True:\n",
    "        batch_features, batch_labels = next(generator)\n",
    "        augmented_data = datagen.flow(batch_features, batch_labels, batch_size=batch_size, shuffle=False)\n",
    "        yield next(augmented_data)\n",
    "\n",
    "train_generator_augmented = augmented_data_generator(train_generator, datagen, BATCH_SIZE)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test if the data generator works\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mtrain_generator\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Test if the data generator works\n",
    "import matplotlib.pyplot as plt\n",
    "x, y = next(train_generator)\n",
    "print(x.shape, y.shape)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i])\n",
    "    plt.title(emotion_map[np.argmax(y[i])])\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
